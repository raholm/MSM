---
title: "Multivariate Statistical Methods"
subtitle: "Assignment 2"
author: "Allan Gholmi, Emma Wallentinsson, Rasmus Holm"
date: "`r Sys.Date()`"
fontsize: 10pt
geometry: margin=1in
output:
    pdf_document:
        toc: false
        number_sections: false
        fig_caption: true
---

```{r global-options, echo = FALSE, eval=TRUE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
knitr::opts_chunk$set(fig.pos='H', fig.align='center')
```

# Question 1

```{r q1-init, echo=FALSE}
data <- read.table("../data/T1-9.dat")
names(data) <- c("country", "100m", "200m", "400m", "800m", "1500m", "3000m", "marathon")
numeric_data <- data[, -1]

countries <- as.character(data$country)
```

# a)

```{r q1-a, echo=FALSE}
X <- as.matrix(numeric_data)
means <- colMeans(X)
covariances <- cov(X)
X_central <- X - rep(1, nrow(X)) %*% t(means)

mdist_sq <- X_central %*% solve(covariances) %*% t(X_central)
country_mdist <- diag(mdist_sq)

significance_level <- 0.1
p <- ncol(X)
quantile <- qchisq(1 - significance_level, df=p)

outliers <- country_mdist > quantile
print("Outliers without correction")
countries[outliers]
```

No clue what the multiple-testing correction procedure refers to.

# b)

\newpage

# Question 2

```{r q2-init, echo=FALSE}
data <- read.table("../data/T5-12.DAT")
```

## a)

```{r q2-a, echo=FALSE, fig.height=6, fig.width=6}
x_bar <- colMeans(data)
S <- cov(data)
S_inv <- solve(S)

n <- nrow(data)
p <- ncol(data)

eigen_values <- eigen(S)$values
eigen_vectors <- eigen(S)$vectors

true_mean <- c(190, 275)
confidence_level <- 0.05

half_lengths <- sqrt(eigen_values) * sqrt((p * (n - 1)) / (n * (n - p)) *
                                          qf(1 - confidence_level, df1=p, df2=n - p))

p1 <- x_bar + eigen_vectors[, 1] * half_lengths[1]
p2 <- x_bar - eigen_vectors[, 1] * half_lengths[1]

p3 <- x_bar + eigen_vectors[, 2] * half_lengths[2]
p4 <- x_bar - eigen_vectors[, 2] * half_lengths[2]

x <- c(p1[1], p2[1], p3[1], p4[1])
y <- c(p1[2], p2[2], p3[2], p4[2])

plot(data$V1, data$V2, pch=20)
points(x, y, col="red", pch=20, cex=1.5)
points(true_mean[1], true_mean[2], col="orange", pch=20, cex=1.5)
points(x_bar[1], x_bar[2], col="blue", pch=20, cex=1.5)
segments(rep(x_bar[1], 4), rep(x_bar[2], 4), x, y)
```

## b)

```{r q2-b, echo=FALSE}
Tsq_offset <- sqrt(p * (n - 1) * qf(1 - confidence_level, df1=p, df2=n - p) / (n - p) * diag(S) / n)
Tsq_confidence_interval <- rbind(x_bar - Tsq_offset, x_bar + Tsq_offset)

bonferroni_offset <- sqrt(diag(S) / n) * qt(1 - confidence_level / (2 * p), df=n - 1)
bonferroni_confidence_interval <- rbind(x_bar - bonferroni_offset, x_bar + bonferroni_offset)

print("T-square Intervals")
Tsq_confidence_interval

print("Bonferroni Intervals")
bonferroni_confidence_interval
```

T-square test always gives wider confidence intervals since it takes the correlation between the measured variables into account. Bonferroni intervals are more precise if you are interested in the individual component means, but if you are interested in the overall data mean you should consider the T-square intervals.

## c)

```{r g2-c, echo=FALSE}
plot(data, pch=20)

old <- par(mfrow=c(1, 3))
qqplot(data$V1, data$V2)
qqnorm(data$V1)
qqnorm(data$V2)
par(old)
```

\newpage

# Question 3

```{r q3-init, echo=FALSE}
library(heplots)
library(dplyr)
library(ggplot2)
library(reshape2)

data <- Skulls
numeric_data <- data[, -1]
colors <- as.numeric(data$epoch)
```

# a)

```{r q3-a, echo=FALSE}
# pairs(numeric_data, col=colors)
mm <- melt(data, id="epoch")
ggplot(mm) +
    geom_boxplot(aes(x=factor(epoch), y=value, fill=variable))
```

# b)

```{r q3-b}
group_means <- data %>%
    group_by(epoch) %>%
    summarise_all(funs(mean(., na.rm=TRUE)))


fit <- manova(cbind(mb, bh, bl, nh) ~ data$epoch, data)
```

# c)

```{r g3-c, echo=FALSE}
residuals <- fit$res
col_names <- c("mb", "bh", "bl", "nh")

old <- par(mfrow=c(2, 2))

for (col in 1:ncol(residuals)) {
    x <- residuals[, col]
    main <- col_names[col]
    h <- hist(x, breaks=25, main=main)
    offset <- (max(x) - min(x)) / 2
    xfit <- seq(min(x) - offset, max(x) + offset, length = 100)
    yfit <- dnorm(xfit, mean = mean(x), sd = sd(x))
    yfit <- yfit * diff(h$mids[1:2]) * length(x)
    lines(xfit, yfit, col="blue", lwd=2)
}

par(old)
```

\newpage

# Appendix

## Code

```{r, eval=FALSE}
# Question 1
<<q1-init>>
<<q1-a>>
<<q1-b>>

# Question 2
<<q2-init>>
<<q2-a>>
<<q2-b>>
<<q2-c>>

# Question 3
<<q3-init>>
<<q3-a>>
<<q3-b>>
<<q3-c>>
```
